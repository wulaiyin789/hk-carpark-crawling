name: Data Fetching
on: 
  push:
  schedule:
    - cron: "*/5 * * * *"
  workflow_dispatch:

jobs:
  Fetch-Route-Data:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
      - name: Setup Python environment
        uses: actions/setup-python@v5
        with:
            python-version: '3.12'
            architecture: 'x64'
            cache: 'pip'
            cache-dependency-path: requirements.txt
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ./requirements.txt
      - name: Crawling resources
        env:
          REQUEST_LIMIT: "6"
        run: |
          set -o xtrace
          python ./parking.py

      - name: Archive crawling outputs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: Crawled Files
          retention-days: 14
          path: |
            dist/carpark_data.json
      - name: Update MD5
        run: |
          md5sum dist/carpark_data.json | cut -f1 -d ' ' | tr -d $'\n' > dist/carpark_data.md5
      - name: create deployment folder
        run: mkdir -p build
      - name: cp files into deployment folder
        run: |
          cp \
          dist/carpark_data.json \
          dist/carpark_data.md5 \
          build/
      - name: Update resources
        uses: JamesIves/github-pages-deploy-action@v4
        with:
            folder: build
            commit-message: Update resources
            branch: data
            clean: false